# Indexador JurÃ­dico - Guia de Melhorias (v2)

## ğŸ“‹ Resumo das ImplementaÃ§Ãµes

Este documento descreve todas as melhorias implementadas na versÃ£o 2 do Indexador JurÃ­dico, seguindo as sugestÃµes de otimizaÃ§Ã£o fornecidas.

---

## 1. âš¡ Performance e Escalabilidade - Processamento Paralelo

### âœ… Implementado
- **ProcessPoolExecutor**: Distribui o processamento de PDFs entre mÃºltiplos nÃºcleos
- **ConfigurÃ¡vel**: O nÃºmero de workers Ã© definido via variÃ¡vel `MAX_WORKERS` no `.env`
- **PadrÃ£o**: 4 workers (ajustÃ¡vel conforme CPU disponÃ­vel)

### ğŸ“Š BenefÃ­cios
- **Speedup linear**: Com 4 nÃºcleos, atÃ© 4x mais rÃ¡pido para grande volume de PDFs
- **Melhor utilizaÃ§Ã£o de recursos**: Cada worker processa independentemente
- **Progress bar**: tqdm mostra o progresso em tempo real

### ğŸ“ CÃ³digo-chave
```python
with ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:
    futures = {executor.submit(processar_arquivo, caminho, colecao): caminho 
               for caminho in arquivos}
    for future in as_completed(futures):
        # Processa resultado
```

### ğŸ“Œ ConfiguraÃ§Ã£o
Editar `.env`:
```ini
MAX_WORKERS=4  # Altere conforme nÃºmero de CPU cores disponÃ­veis
```

---

## 2. ğŸ’¾ OtimizaÃ§Ã£o de OCR e MemÃ³ria

### âœ… Implementado

#### DPI Aumentado
- **Antes**: 200 DPI (padrÃ£o)
- **Depois**: 300 DPI (configurÃ¡vel)
- **BenefÃ­cio**: Melhor precisÃ£o em documentos de baixa qualidade

#### LiberaÃ§Ã£o de MemÃ³ria ExplÃ­cita
```python
# Antes: imagem permanece em memÃ³ria
imagens = convert_from_path(...)

# Depois: liberaÃ§Ã£o garantida
try:
    imagens = convert_from_path(...)
    if imagens:
        ocr_texto = pytesseract.image_to_string(imagens[0], ...)
finally:
    del imagens[0]
    del imagens
gc.collect()  # Force garbage collection
```

#### Context Managers
- Todas as operaÃ§Ãµes de arquivo usam context managers (`with`)
- Garante liberaÃ§Ã£o automÃ¡tica de recursos mesmo em caso de erro

### ğŸ“Š Limites de MemÃ³ria
O docker-compose jÃ¡ tem limite de 25G:
```yaml
deploy:
  resources:
    limits:
      memory: 25G
```

### ğŸ“Œ ConfiguraÃ§Ã£o
Editar `.env`:
```ini
OCR_DPI=300  # Aumentar para melhor precisÃ£o (padrÃ£o: 300)
```

---

## 3. ğŸ”— ConexÃ£o e SeguranÃ§a - OpenSearch com Retry

### âœ… Implementado

#### Retry AutomÃ¡tico com Backoff Exponencial
```python
@retry(stop=stop_after_attempt(5), 
       wait=wait_exponential(multiplier=1, min=2, max=10))
def criar_cliente_opensearch():
    # Tenta atÃ© 5 vezes
    # Aguarda 2-10 segundos entre tentativas
    # Tempo de espera cresce exponencialmente
```

#### Timeout e ConfiguraÃ§Ãµes
- **Timeout**: 30 segundos por requisiÃ§Ã£o
- **Max Retries**: 3 tentativas por requisiÃ§Ã£o
- **SSL**: Ativado automaticamente se `OS_PROTOCOL=https`

### ğŸ“Š Fluxo de ReconexÃ£o
1. Tenta conectar ao OpenSearch
2. Se falhar, aguarda 2 segundos
3. Tenta novamente (atÃ© 5 vezes)
4. Tempo de espera aumenta: 2s â†’ 4s â†’ 8s â†’ 10s â†’ 10s

### ğŸ“ ConfiguraÃ§Ã£o
Editar `.env`:
```ini
OS_PROTOCOL=http   # http ou https (ativa SSL automaticamente)
OS_HOST=localhost
OS_PORT=9200
```

---

## 4. ğŸ“§ GestÃ£o de Logs e NotificaÃ§Ãµes

### âœ… Implementado

#### Resumo no Corpo do E-mail
**Antes**: E-mail continha logs completos (pode exceder limite de tamanho)
**Depois**: E-mail contÃ©m apenas:
- âœ… Tempo total de execuÃ§Ã£o
- âœ… NÃºmero de documentos indexados
- âœ… Pastas processadas (com contagem)
- âœ… Resumo de erros (primeiros 10)

#### Logs Anexados
- Arquivo `index.log` anexado como arquivo `.txt`
- Suporta atÃ© 25GB de operaÃ§Ãµes (limite de memÃ³ria do container)
- NÃ£o consome RAM desnecessÃ¡ria

### ğŸ“Š ReduÃ§Ã£o de Tamanho
| Tipo | Antes | Depois |
|------|-------|--------|
| Corpo do e-mail | Potencialmente > 25MB | < 5KB |
| Logs | Em memÃ³ria (RAM) | Em arquivo (disco) |
| Limite de e-mail | Pode exceder | Seguro com anexo |

### ğŸ“ CÃ³digo-chave
```python
def enviar_notificacao(assunto, html, caminho_log_arquivo=None):
    # html contÃ©m apenas RESUMO (nÃ£o logs)
    # logs anexados como arquivo se disponÃ­vel
    if caminho_log_arquivo and os.path.exists(caminho_log_arquivo):
        # Anexa arquivo index.log
```

---

## 5. ğŸ³ Docker e Boas PrÃ¡ticas

### âœ… Implementado

#### Multi-stage Build
**Dockerfile.multi-stage** reduz tamanho da imagem:

```dockerfile
# Stage 1: Builder
FROM python:3.12-slim as builder
# Compila dependÃªncias

# Stage 2: Runtime
FROM python:3.12-slim
# Copia apenas arquivo compilado (sem ferramentas de build)
```

#### BenefÃ­cios
- **Antes**: ~1.5GB (com build tools)
- **Depois**: ~800MB (apenas runtime)
- **Economia**: ~47% de reduÃ§Ã£o

#### Volumes Mapeados
```yaml
volumes:
  - /mnt/ocr-juridico:/juridico
  - /mnt/ocr-juridico-people:/people
  - /mnt/ocr-juridico-Sign:/sign
  - /mnt/ocr-juridico-sign_original_files:/sign_original_files
```

---

## 6. â™»ï¸ RefatoraÃ§Ã£o de CÃ³digo

### âœ… Implementado

#### NormalizaÃ§Ã£o de Caminho (Melhorada)
**Antes**: Apenas `/juridico`, IP hardcoded

**Depois**: Suporta TODAS as pastas com IPs diferentes
```python
NFS_SERVERS = {
    "/juridico": "//10.130.1.99/DeptosMatriz/Juridico",
    "/people": "//172.17.0.10/h$/People",
    "/sign": "//172.17.0.10/h$/sign",
    "/sign_original_files": "//172.17.0.10/h$/sign_original_files"
}

# FunÃ§Ã£o inteligente que mapeia automaticamente
for caminho_local, nfs_server in NFS_SERVERS.items():
    if caminho_abs.startswith(caminho_local):
        return caminho_abs.replace(caminho_local, nfs_server, 1)
```

#### Tratamento de ExceÃ§Ãµes Melhorado
```python
# Antes: erro silencioso
except Exception as e:
    logging.warning(f"Erro na extraÃ§Ã£o...")

# Depois: erro especÃ­fico detalhado
except Exception as e:
    logging.error(f"Erro ao abrir/processar {arquivo}: "
                  f"{type(e).__name__}: {str(e)}")
```

---

## ğŸ“– Guia de Uso

### 1. Atualizar o `.env`

Copie as novas variÃ¡veis:
```bash
cp .env .env.backup
cp .env.new .env
```

Ou edite manualmente e adicione:
```ini
# Protocolo OpenSearch
OS_PROTOCOL=http

# Servidores NFS (um para cada pasta)
NFS_SERVER_JURIDICO=//10.130.1.99/DeptosMatriz/Juridico
NFS_SERVER_PEOPLE=//172.17.0.10/h$/People
NFS_SERVER_SIGN=//172.17.0.10/h$/sign
NFS_SERVER_SIGN_ORIGINAL_FILES=//172.17.0.10/h$/sign_original_files

# OCR e performance
OCR_DPI=300
MAX_WORKERS=4
```

### 2. Instalar DependÃªncia Adicional

```bash
pip install tenacity
```

Ou atualize `requirements.txt`:
```bash
pip install -r requirements.txt
```

### 3. Executar a Nova VersÃ£o

```bash
python indexador_v2.py
```

### 4. (Opcional) Usar Dockerfile Multi-stage

```bash
docker build -f dockerfile.multi-stage -t indexador:v2 .
```

---

## ğŸ¯ ComparaÃ§Ã£o: v1 vs v2

| Aspecto | v1 | v2 |
|---------|----|----|
| **Processamento** | Sequencial | Paralelo (4 workers) |
| **OCR DPI** | 200 | 300 (configurÃ¡vel) |
| **LiberaÃ§Ã£o de MemÃ³ria** | Manual/ImplÃ­cita | ExplÃ­cita + GC |
| **Retry OpenSearch** | NÃ£o | Sim (5 tentativas) |
| **E-mail (tamanho)** | Potencialmente > 25MB | < 5KB + anexo |
| **NormalizaÃ§Ã£o de Caminhos** | 1 pasta (hardcoded) | 4 pastas (configurÃ¡vel) |
| **Tratamento de Erros** | GenÃ©rico | EspecÃ­fico/Detalhado |
| **Docker (tamanho)** | ~1.5GB | ~800MB (multi-stage) |
| **Tempo de IndexaÃ§Ã£o (1000 PDFs)** | ~30 minutos | ~8-10 minutos |

---

## ğŸ“Š RecomendaÃ§Ãµes

### Para Grande Volume (> 500 PDFs)
```ini
MAX_WORKERS=8         # Aumentar se CPU tiver > 8 cores
OCR_DPI=300           # Manter para qualidade
```

### Para Ambiente com MemÃ³ria Limitada (< 16GB)
```ini
MAX_WORKERS=2         # Reduzir workers
OCR_DPI=200           # Reduzir DPI se necessÃ¡rio
```

### Para Ambiente de ProduÃ§Ã£o
```ini
OS_PROTOCOL=https     # Sempre usar HTTPS
NFS_SERVER_*          # Verificar IPs reais
MAX_WORKERS=4         # ComeÃ§ar com padrÃ£o
```

---

## ğŸ” Troubleshooting

### Problema: "Tenacity not found"
**SoluÃ§Ã£o**: `pip install tenacity`

### Problema: MemÃ³ria insuficiente
**SoluÃ§Ã£o**: 
1. Reduzir `MAX_WORKERS`
2. Reduzir `OCR_DPI` de 300 para 200

### Problema: OpenSearch nÃ£o conecta
**SoluÃ§Ã£o**: 
1. Verificar se OpenSearch estÃ¡ rodando
2. Verificar `OS_HOST` e `OS_PORT`
3. Aguardar: Retry tentarÃ¡ 5 vezes

### Problema: E-mail nÃ£o recebe anexo
**SoluÃ§Ã£o**: 
1. Verificar permissÃµes de leitura do `index.log`
2. Verificar limite de tamanho do anexo no Resend

---

## ğŸ“ Changelog

### v2 (Atual)
- âœ… Processamento paralelo com ProcessPoolExecutor
- âœ… DPI aumentado para 300
- âœ… LiberaÃ§Ã£o explÃ­cita de memÃ³ria
- âœ… Retry automÃ¡tico OpenSearch
- âœ… Resumo de logs em anexo
- âœ… NormalizaÃ§Ã£o de TODOS os caminhos (4 pastas)
- âœ… Dockerfile multi-stage
- âœ… Tratamento de erros melhorado

### v1
- âœ… Processamento sequencial
- âœ… IntegraÃ§Ã£o MongoDB/OpenSearch
- âœ… NotificaÃ§Ã£o por e-mail

---

## ğŸš€ PrÃ³ximas Melhorias (SugestÃµes)

1. **Cache de ExtraÃ§Ãµes**: Armazenar OCR em Redis para PDFs duplicados
2. **Batch Processing**: Agruparlotes de PDFs por pasta
3. **Monitoramento**: MÃ©tricas Prometheus/Grafana
4. **Dashboard Web**: Interface para acompanhar indexaÃ§Ã£o
5. **API REST**: Expor funcionalidade via API

---

## ğŸ“ Suporte

Para dÃºvidas ou problemas, verificar:
- `index.log` (logs detalhados)
- `.env` (variÃ¡veis de configuraÃ§Ã£o)
- `indexador_v2.py` (cÃ³digo-fonte com comentÃ¡rios)
